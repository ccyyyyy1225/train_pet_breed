{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 寵物品種辨識（Pet Breed Classification）\\n\\n本 Notebook 以 **每類 5 張圖片** 的小樣本資料，示範如何用 **ResNet18 Transfer Learning** 訓練可展示的品種辨識模型，並輸出評估圖表與可部署模型（TorchScript）。"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 0. 安裝套件（Colab）"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": ""
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": "!pip -q install torch torchvision scikit-learn matplotlib opencv-python-headless tqdm\nimport torch, torchvision\nprint('torch:', torch.__version__)\nprint('torchvision:', torchvision.__version__)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. 準備資料\\n\\n請確認你的資料夾為：\\n\\n```\ndataset/<class>/*.jpg\n```\\n\\n例如：\\n- dataset/Shiba Inu/xxx.jpg\\n- dataset/Ragdoll/yyy.png\\n\\n接著我們自動切成 train/val/test（3/1/1）。"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": ""
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": "import os, random, shutil\nfrom pathlib import Path\n\nSRC_ROOT = Path(\"dataset\")\nDST_ROOT = Path(\"data_split\")\nSEED = 42\nRATIOS = (3,1,1)  # train/val/test = 3/1/1\n\nrandom.seed(SEED)\n\nassert SRC_ROOT.exists(), f\"找不到資料夾：{SRC_ROOT.resolve()}\"\nclasses = [p for p in SRC_ROOT.iterdir() if p.is_dir()]\nprint(\"Classes:\", [c.name for c in classes])\n\n# 建立輸出結構\nfor split in [\"train\",\"val\",\"test\"]:\n    for cls in classes:\n        (DST_ROOT / split / cls.name).mkdir(parents=True, exist_ok=True)\n\n# 分割並複製\nfor cls in classes:\n    files = [p for p in cls.iterdir() if p.is_file()]\n    if len(files) < sum(RATIOS):\n        raise ValueError(f\"類別 {cls.name} 圖片不足：{len(files)} < {sum(RATIOS)}\")\n    random.shuffle(files)\n\n    train_files = files[:RATIOS[0]]\n    val_files   = files[RATIOS[0]:RATIOS[0]+RATIOS[1]]\n    test_files  = files[RATIOS[0]+RATIOS[1]:RATIOS[0]+RATIOS[1]+RATIOS[2]]\n\n    for p in train_files:\n        shutil.copy2(p, DST_ROOT/\"train\"/cls.name/p.name)\n    for p in val_files:\n        shutil.copy2(p, DST_ROOT/\"val\"/cls.name/p.name)\n    for p in test_files:\n        shutil.copy2(p, DST_ROOT/\"test\"/cls.name/p.name)\n\nprint(\"[OK] 分割完成 ->\", DST_ROOT.resolve())\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. DataLoader 與資料增強（小樣本關鍵）"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": ""
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": "import torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\nIMG_SIZE = 224\nBATCH_SIZE = 8  # 小資料集不需要太大\nNUM_WORKERS = 2\n\ntrain_tfm = transforms.Compose([\n    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.02),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n])\n\neval_tfm = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n])\n\ntrain_ds = datasets.ImageFolder(\"data_split/train\", transform=train_tfm)\nval_ds   = datasets.ImageFolder(\"data_split/val\", transform=eval_tfm)\ntest_ds  = datasets.ImageFolder(\"data_split/test\", transform=eval_tfm)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\nval_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\ntest_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\nclass_names = train_ds.classes\nnum_classes = len(class_names)\nprint(\"num_classes =\", num_classes)\nprint(\"classes =\", class_names)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. 建立模型（ResNet18 Transfer Learning）\\n\\n策略：\\n1) 先凍結 backbone，只訓練最後 fc\\n2) 若需要再微調 layer4（較保守，小 LR）"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": ""
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": "import torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"device:\", device)\n\nmodel = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n# 凍結 backbone\nfor p in model.parameters():\n    p.requires_grad = False\n\n# 替換分類層\nin_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features, num_classes)\n\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n\nmodel\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. 訓練迴圈（含 Early Stopping）"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": ""
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": "from tqdm import tqdm\nimport numpy as np\n\ndef run_epoch(model, loader, train: bool):\n    if train:\n        model.train()\n    else:\n        model.eval()\n\n    total_loss = 0.0\n    correct = 0\n    total = 0\n\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n\n        if train:\n            optimizer.zero_grad(set_to_none=True)\n\n        with torch.set_grad_enabled(train):\n            logits = model(x)\n            loss = criterion(logits, y)\n\n            if train:\n                loss.backward()\n                optimizer.step()\n\n        total_loss += loss.item() * x.size(0)\n        pred = logits.argmax(dim=1)\n        correct += (pred == y).sum().item()\n        total += x.size(0)\n\n    return total_loss/total, correct/total\n\nEPOCHS = 30\npatience = 5\nbest_val = -1\nbest_state = None\nwait = 0\n\nhistory = {\"train_loss\":[], \"train_acc\":[], \"val_loss\":[], \"val_acc\":[]}\n\nfor epoch in range(1, EPOCHS+1):\n    tr_loss, tr_acc = run_epoch(model, train_loader, train=True)\n    va_loss, va_acc = run_epoch(model, val_loader, train=False)\n\n    history[\"train_loss\"].append(tr_loss)\n    history[\"train_acc\"].append(tr_acc)\n    history[\"val_loss\"].append(va_loss)\n    history[\"val_acc\"].append(va_acc)\n\n    print(f\"Epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.3f} | val loss {va_loss:.4f} acc {va_acc:.3f}\")\n\n    if va_acc > best_val:\n        best_val = va_acc\n        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n        wait = 0\n    else:\n        wait += 1\n        if wait >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n# 載入最佳模型\nmodel.load_state_dict(best_state)\nprint(\"Best val acc =\", best_val)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. 繪製 Learning Curves"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": ""
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": "import matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(history[\"train_loss\"], label=\"train_loss\")\nplt.plot(history[\"val_loss\"], label=\"val_loss\")\nplt.legend()\nplt.title(\"Loss Curve\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.show()\n\nplt.figure()\nplt.plot(history[\"train_acc\"], label=\"train_acc\")\nplt.plot(history[\"val_acc\"], label=\"val_acc\")\nplt.legend()\nplt.title(\"Accuracy Curve\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"accuracy\")\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. 測試集評估：Confusion Matrix + Classification Report"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": ""
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.metrics import confusion_matrix, classification_report\n\nmodel.eval()\nall_y = []\nall_pred = []\n\nwith torch.no_grad():\n    for x, y in test_loader:\n        x = x.to(device)\n        logits = model(x)\n        pred = logits.argmax(dim=1).cpu().numpy()\n        all_pred.extend(pred.tolist())\n        all_y.extend(y.numpy().tolist())\n\ncm = confusion_matrix(all_y, all_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(all_y, all_pred, target_names=class_names))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. 匯出模型給 Streamlit（TorchScript）"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": ""
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": "import os, json\nimport torch\n\nEXPORT_DIR = \"exports\"\nos.makedirs(EXPORT_DIR, exist_ok=True)\n\n# TorchScript（Trace）— 方便 Streamlit 直接 load\nexample = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\ntraced = torch.jit.trace(model, example)\nmodel_path = os.path.join(EXPORT_DIR, \"model_resnet18.pt\")\ntraced.save(model_path)\n\n# 類別名稱\nclass_path = os.path.join(EXPORT_DIR, \"class_names.json\")\nwith open(class_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(class_names, f, ensure_ascii=False, indent=2)\n\nprint(\"Saved:\", model_path)\nprint(\"Saved:\", class_path)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. 單張圖片快速測試（Top-3）"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": ""
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": "from PIL import Image\nimport numpy as np\n\ndef predict_image(img_path, topk=3):\n    img = Image.open(img_path).convert(\"RGB\")\n    x = eval_tfm(img).unsqueeze(0).to(device)\n    with torch.no_grad():\n        logits = model(x)\n        probs = torch.softmax(logits, dim=1).cpu().numpy().squeeze()\n    idx = probs.argsort()[::-1][:topk]\n    return [(class_names[i], float(probs[i])) for i in idx]\n\n# 找一張 test 圖片\nsample = None\nfor root, _, files in os.walk(\"data_split/test\"):\n    for fn in files:\n        sample = os.path.join(root, fn)\n        break\n    if sample:\n        break\n\nprint(\"Sample:\", sample)\nprint(predict_image(sample, topk=3))\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "name": "train_pet_breed.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}